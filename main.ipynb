{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importando as bibliotecas necessárias para analisar os dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import openpyxl.utils.cell as cell\n",
    "\n",
    "\n",
    "#import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando os dados\n",
    "data_frame = pd.read_excel('BANCO DE DADOS - INVERTIDO - 24 de Agosto 2019.xlsx')\n",
    "\n",
    "def number_to_excel_column(num):\n",
    "    \"\"\"\n",
    "    Converte um número de coluna em uma string com a representação alfabética.\n",
    "    Exemplo: 1 => 'A', 2 => 'B', ..., 26 => 'Z', 27 => 'AA', 28 => 'AB', ...\n",
    "    \"\"\"\n",
    "    return cell.get_column_letter(num)\n",
    "\n",
    "# Gera uma lista com os nomes das colunas no estilo do Excel\n",
    "col_names = [number_to_excel_column(num) for num in range(1, len(data_frame.columns)+1)]\n",
    "\n",
    "# Cria um dicionário com os nomes atuais e os novos nomes das colunas\n",
    "new_col_names = {old_name: new_name for old_name, new_name in zip(data_frame.columns, col_names)}\n",
    "\n",
    "# Renomeia as colunas\n",
    "data_frame = data_frame.rename(columns=new_col_names)\n",
    "\n",
    "# Cria uma lista com os nomes das colunas que devem ser removidas\n",
    "col_names = []\n",
    "\n",
    "data_frame_r = data_frame.replace('', np.nan)\n",
    "\n",
    "\n",
    "# Parte do dataframe que contem o questionário de \"Social\"\n",
    "df_socioeconomico = data_frame_r.loc[:, 'B':'BP']\n",
    "# Somar colunas que envolvem o uso de drogas\n",
    "df_socioeconomico = df_socioeconomico.assign(USO_DROGAS=df_socioeconomico.loc[:, 'BF':'BN'].sum(axis=1))\n",
    "\n",
    "# Parte do dataframe que contem o questionário WHOQOL\n",
    "df_whoqol = data_frame_r.loc[:, 'BR':'CU']\n",
    "\n",
    "# Parte do dataframe que contem o questionário de MHI\n",
    "df_mhi = data_frame_r.loc[:, 'CW':'EH']\n",
    "\n",
    "# Juntando os dataframes\n",
    "df = pd.concat([df_socioeconomico, df_whoqol, df_mhi], axis=1)\n",
    "\n",
    "# Pegar a coluna que tem o curso de cada aluno que será para ser previsto\n",
    "df_curso = df.loc[:, 'K']\n",
    "df = df.drop(columns=['K'])\n",
    "\n",
    "# Concatenando o dataframe com o curso\n",
    "df = pd.concat([df, df_curso], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Veficicando Tamnho do dataframe\n",
    "print(df.shape)\n",
    "\n",
    "# Checando se há valores nulos\n",
    "#print(df.isnull().sum())\n",
    "\n",
    "# Removendo linhas com valores nulos\n",
    "df = df.dropna()\n",
    "\n",
    "# Checando quantos elementos foram removidos\n",
    "print('Shape',df.shape)\n",
    "\n",
    "# Separando os dados de X e y\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "\n",
    "#unique, counts = np.unique(y, return_counts=True)\n",
    "#print(np.asarray((unique, counts)).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando a normalização dos dados\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Separando os dados de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criando o modelo de classificação simples e rapido\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Modelo utilizando o KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = model_knn.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Modelo utilizando o SVM\n",
    "from sklearn.svm import SVC\n",
    "model_svm = SVC(kernel='linear', random_state=42, decision_function_shape='ovo')\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = model_svm.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementando grid search do PCA e SVM para encontrar os atributos e parâmetros ideais\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('pca', PCA()), ('svm', SVC(decision_function_shape='ovo'))])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'pca__n_components': np.arange(45, np.shape(X)[1]),\n",
    "        'svm__C': [0.1, 1, 10],\n",
    "        'svm__kernel': ['linear','rbf']\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.score(X_test, y_test))\n",
    "\n",
    "# Selecionando melhores atributos do resultado do grid search\n",
    "pca = PCA(n_components=grid.best_params_['pca__n_components'])\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Criando modelo SVM com os melhores parâmetros\n",
    "model_svm = SVC(kernel=grid.best_params_['svm__kernel'], C=grid.best_params_['svm__C'], random_state=42)\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = model_svm.predict(X_test)\n",
    "\n",
    "# Avaliando modelo com metricas relevantes\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modelo utilizando o XGBoost\n",
    "# from xgboost import XGBClassifier\n",
    "# model_xgb = XGBClassifier()\n",
    "# model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# # Fazendo as previsões\n",
    "# y_pred = model_xgb.predict(X_test)\n",
    "\n",
    "# # Avaliando o modelo\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# print(accuracy_score(y_test, y_pred))\n",
    "# #print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Modelo utilizando o LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "model_lgbm = LGBMClassifier()\n",
    "model_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = model_lgbm.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Modelo utilizando o MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model_mlp = MLPClassifier()\n",
    "model_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = model_mlp.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Modelo que seleciona aleatoriamente a classe a fim de comparar com os modelos acima\n",
    "from sklearn.dummy import DummyClassifier\n",
    "model_dummy = DummyClassifier(strategy='stratified')\n",
    "model_dummy.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = model_dummy.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementando Grid Seach com MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100, 100, 100), (100, 100), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "clf = GridSearchCV(mlp, param_grid, cv=5, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Criando modelo MLP com os melhores parâmetros\n",
    "model_mlp = MLPClassifier(hidden_layer_sizes=clf.best_params_['hidden_layer_sizes'], activation=clf.best_params_['activation'], solver=clf.best_params_['solver'], alpha=clf.best_params_['alpha'], learning_rate=clf.best_params_['learning_rate'], max_iter=1000)\n",
    "model_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = model_mlp.predict(X_test)\n",
    "\n",
    "# Avaliando modelo com metricas relevantes\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementando AutoML\n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(verbosity=2, n_jobs=-1)\n",
    "tpot.fit(X_train, y_train)\n",
    "tpot.export('tpot_pipeline.py')\n",
    "print(tpot.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = tpot.predict(X_test)\n",
    "\n",
    "# Avaliando modelo com metricas relevantes\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegar melhor modelo do AutoML[\n",
    "print(tpot.fitted_pipeline_)\n",
    "print(tpot.fitted_pipeline_.steps[0][1].get_params())\n",
    "#print(tpot.fitted_pipeline_.steps[1][1].get_params())\n",
    "\n",
    "# Testando modelo com os melhores parâmetros do AutoML\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(bootstrap=tpot.fitted_pipeline_.steps[0][1].get_params()['bootstrap'], max_features=tpot.fitted_pipeline_.steps[0][1].get_params()['max_features'], min_samples_leaf=tpot.fitted_pipeline_.steps[0][1].get_params()['min_samples_leaf'], min_samples_split=tpot.fitted_pipeline_.steps[0][1].get_params()['min_samples_split'], n_estimators=tpot.fitted_pipeline_.steps[0][1].get_params()['n_estimators'])\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_pred = model_rf.predict(X_test)\n",
    "\n",
    "# Avaliando modelo com metricas relevantes\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
