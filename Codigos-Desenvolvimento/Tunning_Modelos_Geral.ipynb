{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning dos hiperparâmetros\n",
    "- Será realizado o tunning para os seguintes casos:\n",
    "    1) sem informações do WHOQOL na base\n",
    "    2) com todas as respostas do WHOQOL\n",
    "    3) só com o índice final do WHOQOL\n",
    "    4) só com os índices dos domínios do WHOQOL\n",
    "\n",
    "- Para os seguintes modelos:\n",
    "    1) Random Forest\n",
    "    2) SVM\n",
    "    3) MLP\n",
    "    4) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow:\n",
    "Para cada caso:\n",
    "- Importar dados\n",
    "- Separar em treino e teste ( Preciso\n",
    "- Definir os parâmetros a serem testados\n",
    "- Realizar o tunning\n",
    "- Salvar os resultados graficamente\n",
    "- Salvar o melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:53:08.468641149Z",
     "start_time": "2023-11-17T00:53:08.016363570Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tpot import TPOTClassifier\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "\n",
    "#Importando modelo Dummy:\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:53:08.477330564Z",
     "start_time": "2023-11-17T00:53:08.474266089Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_model_tuning(data, target, models, param_grids, base_name):\n",
    "    # Dividir os dados em treinamento e teste após o Random Under-Sampling\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    best_models = {}  # Dicionário para armazenar o melhor modelo de cada tipo\n",
    "    model_accuracies = {}  # Dicionário para armazenar as acurácias de cada modelo\n",
    "    current_dir = os.getcwd()\n",
    "    for model_name, model, param_grid_entry in zip(models.keys(), models.values(), param_grids):\n",
    "        print(f\"Tuning do modelo {model_name} iniciado...\")\n",
    "\n",
    "        # Acessar o dicionário de parâmetros correspondente ao modelo atual\n",
    "        param_grid = param_grid_entry['params']\n",
    "\n",
    "        # Realizar a busca em grid para encontrar os melhores parâmetros\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Melhor modelo encontrado\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões no conjunto de teste\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Calcular a acurácia do modelo\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        model_accuracies[model_name] = accuracy\n",
    "\n",
    "        print(f\"Acurácia do modelo {model_name}: {accuracy:.4f}\")\n",
    "\n",
    "        # Salvar o melhor modelo\n",
    "        best_models[model_name] = best_model\n",
    "\n",
    "    # Plotar gráfico de desempenho comparativo\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(model_accuracies.keys(), model_accuracies.values())\n",
    "    plt.xlabel('Modelos')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.title('Comparação de desempenho dos modelos')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    graph_filename = f\"{base_name}_graph_{model_name}.png\"\n",
    "    graph_path = os.path.join(current_dir, graph_filename)\n",
    "    plt.savefig(graph_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    #Pickle the single best model, verifying the best and saving from best_models dict, se tiver mais algo salvo com o mesmo nome, adiciona mais um.\n",
    "    best_model = max(model_accuracies, key=model_accuracies.get)\n",
    "    best_model = best_models[best_model]\n",
    "    if os.path.exists(f\"{base_name}_best_model.pkl\"):\n",
    "        i = 1\n",
    "        while os.path.exists(f\"{base_name}_best_model_{i}.pkl\"):\n",
    "            i += 1\n",
    "        pickle.dump(best_model, open(f\"{base_name}_best_model_{i}.pkl\", \"wb\"))\n",
    "    else:\n",
    "        pickle.dump(best_model, open(f\"{base_name}_best_model.pkl\", \"wb\"))\n",
    "    # Salvar tabela com os valores de acurácia\n",
    "    table_filename = f\"{base_name}_table_{model_name}.csv\"\n",
    "    accuracies_df = pd.DataFrame.from_dict(model_accuracies, orient='index', columns=['Acurácia'])\n",
    "    table_path = os.path.join(current_dir, table_filename)\n",
    "    accuracies_df.to_csv(table_path, index=False)\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.478996100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sem WHOQOL:\n",
    "base1 = pd.read_csv('Datasets/dataframe_socioeconomico_Niveis.csv')\n",
    "data1 = base1.drop('Nivel_MHI', axis=1)\n",
    "target1 = base1['Nivel_MHI']\n",
    "le = LabelEncoder()\n",
    "target1 = le.fit_transform(target1)\n",
    "\n",
    "# Realizar Random Under-Sampling\n",
    "sampler = RandomUnderSampler()\n",
    "data1_re, target1_re = sampler.fit_resample(data1, target1)\n",
    "\n",
    "\n",
    "# com todas as respostas do WHOQOL\n",
    "base2 = pd.read_csv('Datasets/df_social_whoqol_tratado_1.csv')\n",
    "data2 = base2.drop('Nivel_MHI', axis=1)\n",
    "target2 = base2['Nivel_MHI']\n",
    "target2 = le.fit_transform(target2)\n",
    "sampler = RandomUnderSampler()\n",
    "data2_re, target2_re = sampler.fit_resample(data2, target2)\n",
    "\n",
    "\n",
    "# só com o indice dos dominiosdo WHOQOL, concatenar base1 com final da base2\n",
    "data3 = pd.concat([data1, base2.loc[:,['CR','CS','CT','CU']]], axis=1)\n",
    "target3 = base2['Nivel_MHI']\n",
    "target3 = le.fit_transform(target3)\n",
    "sampler = RandomUnderSampler()\n",
    "data3_re, target3_re = sampler.fit_resample(data3, target3)\n",
    "\n",
    "\n",
    "# Só com a qualidade de vida do WHOQOL\n",
    "data4 = pd.concat([data1, base2['BR']], axis=1)\n",
    "target4 = base2['Nivel_MHI']\n",
    "target4 = le.fit_transform(target4)\n",
    "sampler = RandomUnderSampler()\n",
    "data4_re, target4_re = sampler.fit_resample(data4, target4)\n",
    "\n",
    "# Qualidade de Vida Geral ( Media das duas primeiras questões do WHOQOL)\n",
    "# Pegar a média das duas primeiras colunas da base2, pelo indice\n",
    "data5 = pd.concat([data1, base2.loc[:,['BR','BS']].mean(axis=1)], axis=1)\n",
    "target5 = base2['Nivel_MHI']\n",
    "target5 = le.fit_transform(target5)\n",
    "sampler = RandomUnderSampler()\n",
    "data5.columns = data5.columns.astype(str)\n",
    "data5_re, target5_re = sampler.fit_resample(data5, target5)\n",
    "\n",
    "# Media de todos os dominios do WHOQOL\n",
    "data6 = pd.concat([data1, base2.loc[:,['CR','CS','CT','CU']].mean(axis=1)], axis=1)\n",
    "target6 = base2['Nivel_MHI']\n",
    "target6 = le.fit_transform(target6)\n",
    "sampler = RandomUnderSampler()\n",
    "data6.columns = data6.columns.astype(str)\n",
    "data6_re, target6_re = sampler.fit_resample(data6, target6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:53:08.486640807Z",
     "start_time": "2023-11-17T00:53:08.482018196Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dividir os dados em treino e teste\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(data1_re, target1_re, test_size=0.2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(data2_re, target2_re, test_size=0.2)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(data3_re, target3_re, test_size=0.2)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(data4_re, target4_re, test_size=0.2)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(data5_re, target5_re, test_size=0.2)\n",
    "X_train6, X_test6, y_train6, y_test6 = train_test_split(data6_re, target6_re, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.521906434Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avalia_modelo_cv(model, X_input, y_input, n, resultados_individuais=False):\n",
    "    kf = KFold(n_splits=n)\n",
    "    reports = []\n",
    "    y_true = []\n",
    "    y_pred_list = []\n",
    "    X_array = X_input.values\n",
    "    accuracy_list = []\n",
    "    model_name = type(model).__name__\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X_input)):\n",
    "        X_input, X_test = X_array[train_index], X_array[test_index]\n",
    "        y_train, y_test = y_input[train_index], y_input[test_index]\n",
    "        model.fit(X_input, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_true.extend(y_test)\n",
    "        y_pred_list.append(y_pred)\n",
    "        report = classification_report(y_test, y_pred, zero_division=0)\n",
    "        reports.append(report)\n",
    "        accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "        if resultados_individuais:\n",
    "            print(f\"Classification Report for fold {fold_idx + 1}:\\n{report}\\n\")\n",
    "    y_pred_total = np.concatenate(y_pred_list)\n",
    "    print(\"-\" * 45)\n",
    "    print(\"model_name: \", model_name)\n",
    "    print(\"Average Classification Report:\")\n",
    "    avg_report = classification_report(y_true, y_pred_total, zero_division=0)\n",
    "    print(avg_report)\n",
    "    #Retorna a acuracia media\n",
    "    return accuracy_score(y_true, y_pred_total)\n",
    "\n",
    "\n",
    "# Função que chama os 4 modelos e retorna o resultado de cada um usando a função avalia_modelo_cv e imprime o resultado de cada um.\n",
    "\n",
    "def avalia_dif_modelos_cv(X_train, y_test, cv):\n",
    "    # Criando os modelos\n",
    "    dummy_av = DummyClassifier(strategy='most_frequent')\n",
    "    rf_av = RandomForestClassifier(n_jobs=-1)\n",
    "    svm_av = SVC(kernel='rbf', gamma='auto', decision_function_shape='ovo')\n",
    "    mlp_av = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000)\n",
    "    xgb_av = XGBClassifier(n_jobs=-1)\n",
    "\n",
    "    # Aplicando a função de avaliação\n",
    "    dummy_fun_av = avalia_modelo_cv(dummy_av, X_train, y_test, cv)\n",
    "    rf_fun_av = avalia_modelo_cv(rf_av, X_train, y_test, cv)\n",
    "    svm_fun_av = avalia_modelo_cv(svm_av, X_train, y_test, cv)\n",
    "    mlp_fun_av = avalia_modelo_cv(mlp_av, X_train, y_test, cv)\n",
    "    xgb_fun_av = avalia_modelo_cv(xgb_av, X_train, y_test, cv)\n",
    "\n",
    "    # Criando o dataframe com os resultados\n",
    "    df_resultado = pd.DataFrame({'Modelo': ['Dummy', 'RF', 'SVM', 'MLP', 'XGB'],\n",
    "                                 'Acurácia': [dummy_fun_av, rf_fun_av, svm_fun_av, mlp_fun_av, xgb_fun_av]})\n",
    "\n",
    "    # Plotando o gráfico de barras, que vai de 0 a 1\n",
    "    sns.barplot(x='Modelo', y='Acurácia', data=df_resultado)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show(\"Desempenho dos modelos\")\n",
    "    %matplotlib inline\n",
    "\n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Avaliando modelos sem Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.522931074Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(data1, target1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.524053708Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(data2, target2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T00:53:08.636158261Z",
     "start_time": "2023-11-17T00:53:08.524962743Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(data3, target3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.525903287Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(data4, target4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.526771436Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(data5, target5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.528050671Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(data6, target6, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Avaliando modelos com Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.528863417Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Avaliando os modelos para cada dado com o treino\n",
    "avalia_dif_modelos_cv(X_train1, y_train1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.529664582Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(X_train2, y_train2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.530437864Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(X_train3, y_train3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.531370123Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(X_train4, y_train4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.532269049Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(X_train5, y_train5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.533025680Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avalia_dif_modelos_cv(X_train6, y_train6, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.534127525Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definindo parametros:\n",
    "# Definir os modelos e os grids de parâmetros\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'MLP': MLPClassifier(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "\n",
    "param_grids = [\n",
    "    {\n",
    "        'model': 'Random Forest',\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "            'max_depth': [None, 5, 10, 15, 20],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['auto', 'sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': 'SVM',\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': 'MLP',\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': [(10,), (50,), (100,), (150,), (200,)],\n",
    "            'activation': ['logistic', 'tanh', 'relu'],\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "            'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': 'XGBoost',\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "            'max_depth': [3, 5, 7, 9, 11],\n",
    "            'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.535028074Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criando uma função para avaliar os modelos\n",
    "def avalia_modelo_cv(model, X_input, y_input, n, resultados_individuais=False):\n",
    "    kf = KFold(n_splits=n)\n",
    "    reports = []\n",
    "    y_true = []\n",
    "    y_pred_list = []\n",
    "    X_array = X_input.values\n",
    "    accuracy_list = []\n",
    "    model_name = type(model).__name__\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X_input)):\n",
    "        X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "        y_train, y_test = y_input[train_index], y_input[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_true.extend(y_test)\n",
    "        y_pred_list.append(y_pred)\n",
    "        report = classification_report(y_test, y_pred, zero_division=0)\n",
    "        reports.append(report)\n",
    "        accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "        if resultados_individuais:\n",
    "            print(f\"Classification Report for fold {fold_idx + 1}:\\n{report}\\n\")\n",
    "    y_pred_total = np.concatenate(y_pred_list)\n",
    "    print(\"-\" * 45)\n",
    "    print(\"model_name: \", model_name)\n",
    "    print(\"Average Classification Report:\")\n",
    "    avg_report = classification_report(y_true, y_pred_total, zero_division=0)\n",
    "    print(avg_report)\n",
    "    #Retorna a acuracia media\n",
    "    return accuracy_score(y_true, y_pred_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.535829218Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def perform_cross_validation(model, X, y, cv, verbose=True):\n",
    "    reports = []\n",
    "    predictions = cross_val_predict(model, X, y, cv=cv)\n",
    "\n",
    "    for fold in range(cv):\n",
    "        start = fold * len(X) // cv\n",
    "        end = (fold + 1) * len(X) // cv\n",
    "        report = classification_report(y[start:end], predictions[start:end], output_dict=True)\n",
    "        reports.append(report)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold {fold + 1} Classification Report:\")\n",
    "            print(classification_report(y[start:end], predictions[start:end]))\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    avg_report = {\n",
    "        'precision': np.mean([report['weighted avg']['precision'] for report in reports]),\n",
    "        'recall': np.mean([report['weighted avg']['recall'] for report in reports]),\n",
    "        'f1-score': np.mean([report['weighted avg']['f1-score'] for report in reports]),\n",
    "        'support': np.mean([report['weighted avg']['support'] for report in reports])\n",
    "    }\n",
    "\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "\n",
    "    if verbose or not verbose:\n",
    "        print(\"Average Classification Report:\")\n",
    "        print(classification_report(y, predictions))\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.536912528Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chamando função para cada uma das bases\n",
    "# Aplicando Random Forest no under-sampling com Cross Validation de 10 folds\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = RandomForestClassifier()\n",
    "modelSVM = SVC()\n",
    "#avalia_modelo_cv(model, data1_re, target1_re, 5, True)\n",
    "\n",
    "perform_cross_validation(model, data1_re, target1_re, 5, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.539133600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perform_cross_validation(model, data2_re, target2_re, 5, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.542204307Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perform_cross_validation(model, data3_re, target3_re, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.545533696Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perform_cross_validation(model, data4_re, target4_re, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.549190365Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelMLP = MLPClassifier()\n",
    "perform_cross_validation(modelMLP, data5_re, target5_re, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.552550291Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perform_cross_validation(model, data6_re, target6_re, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.555354401Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chamando função para cada uma das bases\n",
    "print(\"========================== Data 1  =================================\")\n",
    "best_models1 = perform_model_tuning(data1, target1, models, param_grids, \"data1\")\n",
    "#print(\"========================== Data 2  =================================\")\n",
    "#best_models2 = perform_model_tuning(data2, target2, models, param_grids,\"data2\")\n",
    "#print(\"========================== Data 3  =================================\")\n",
    "best_models3 = perform_model_tuning(data3, target3, models, param_grids, \"data3\")\n",
    "print(\"========================== Data 4  =================================\")\n",
    "#best_models4 = perform_model_tuning(data4, target4, models, param_grids, \"data4\")\n",
    "print(\"========================== Data 5  =================================\")\n",
    "#best_models5 = perform_model_tuning(data5, target5, models, param_grids, \"data5\")\n",
    "print(\"========================== Data 6  =================================\")\n",
    "#best_models6 = perform_model_tuning(data6, target6, models, param_grids, \"data6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.607461094Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pegar o melhor modelo de cada base, usando max, para em seguida aplicar SBFS e SFFS com cross validation\n",
    "# para cada um dos modelos\n",
    "#best_model1 = max(best_models1, key=best_models1.get)\n",
    "#modelo1 = best_models1['Random Forest']\n",
    "\n",
    "#best_model2 = max(best_models2, key=best_models2.get)\n",
    "#modelo2 = best_models2['Random Forest']\n",
    "\n",
    "#best_model3 = max(best_models3, key=best_models3.get)\n",
    "#modelo3 = best_models3['Random Forest']\n",
    "\n",
    "#best_model4 = max(best_models4, key=best_models4.get)\n",
    "#modelo4 = best_models4['Random Forest']\n",
    "\n",
    "modelo5 = best_models5['MLP']\n",
    "\n",
    "modelo6 = best_models6['XGBoost']\n",
    "#print(modelo1)\n",
    "#print(modelo2)\n",
    "#print(modelo3)\n",
    "#print(modelo4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.608229277Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Salvando modelo1 à 4 em pickle\n",
    "import pickle\n",
    "#with open('modelo1.pkl', 'wb') as f:\n",
    "#    pickle.dump(modelo1, f)\n",
    "#with open('modelo2.pkl', 'wb') as f:\n",
    "#    pickle.dump(modelo2, f)\n",
    "#with open('modelo3.pkl', 'wb') as f:\n",
    "#    pickle.dump(modelo3, f)\n",
    "#with open('modelo4.pkl', 'wb') as f:\n",
    "#    pickle.dump(modelo4, f)\n",
    "with open('modelo5.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo5, f)\n",
    "with open('modelo6.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo6, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.608905808Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importando modelos pickl\n",
    "import pickle\n",
    "with open('modelo1.pkl', 'rb') as file:\n",
    "    modelo1 = pickle.load(file)\n",
    "    print(f'Modelo1 = \\n{modelo1}')\n",
    "with open('modelo2.pkl', 'rb') as file:\n",
    "    modelo2 = pickle.load(file)\n",
    "    print(f'Modelo2 = \\n{modelo2}')\n",
    "with open('modelo3.pkl', 'rb') as file:\n",
    "    modelo3 = pickle.load(file)\n",
    "    print(f'Modelo3 = \\n{modelo3}')\n",
    "with open('modelo4.pkl', 'rb') as file:\n",
    "    modelo4 = pickle.load(file)\n",
    "    print(f'Modelo4 = \\n{modelo4}')\n",
    "with open('modelo5.pkl', 'rb') as file:\n",
    "    modelo5 = pickle.load(file)\n",
    "    print(f'Modelo5 = \\n{modelo5}')\n",
    "with open('modelo6.pkl', 'rb') as file:\n",
    "    modelo6 = pickle.load(file)\n",
    "    print(f'Modelo6 = \\n{modelo6}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.609572542Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.610295119Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analisar cross validation para cada um dos modelos\n",
    "#print(\"========================== Data 1  =================================\")\n",
    "#c1 = cross_val_score(modelo1, data1_re, target1_re , cv=5)\n",
    "#print(c1)\n",
    "#print(c1.mean())\n",
    "\n",
    "#perform_cross_validation(modelo1, data1_re, target1_re, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.611028847Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"========================== Data 2  =================================\")\n",
    "#c2 = cross_val_score(modelo2, data2_re, target2_re, cv=5)\n",
    "#print(c2)\n",
    "#print(c2.mean())\n",
    "\n",
    "#perform_cross_validation(modelo2, data2_re, target2_re, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.611649064Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"========================== Data 3  =================================\")\n",
    "#c3 = cross_val_score(modelo3, data3_re, target3_re, cv=5)\n",
    "#print(c3)\n",
    "#print(c3.mean())\n",
    "\n",
    "#perform_cross_validation(modelo3, data3_re, target3_re, 5, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.612509749Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"========================== Data 4  =================================\")\n",
    "#c4 = cross_val_score(modelo4, data4_re, target4_re, cv=5)\n",
    "#print(c4)\n",
    "#print(c4.mean())\n",
    "\n",
    "#perform_cross_validation(modelo4, data4_re, target4_re, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.613263284Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"========================== Data 5  =================================\")\n",
    "c5 = cross_val_score(modelo5, data5_re, target5_re, cv=5)\n",
    "print(c5)\n",
    "print(c5.mean())\n",
    "\n",
    "perform_cross_validation(modelo5, data5_re, target5_re, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.614062484Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"========================== Data 6  =================================\")\n",
    "c6 = cross_val_score(modelo6, data6_re, target6_re, cv=5)\n",
    "print(c6)\n",
    "print(c6.mean())\n",
    "\n",
    "perform_cross_validation(modelo6, data6_re, target6_re, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.614677351Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# Função para aplicar SBFS e SFFS com cross validation e salvar tabela com resultado.\n",
    "def perform_feature_selection(data, target, model, best_model, method, cv):\n",
    "    # Criando o objeto de seleção de features\n",
    "    if method == 'SBFS':\n",
    "        sfs = SFS(model,\n",
    "                  k_features=\"best\",\n",
    "                  forward=False,\n",
    "                  floating=True,\n",
    "                  verbose=2,\n",
    "                  scoring='accuracy',\n",
    "                  cv=cv,\n",
    "                  n_jobs=-1)\n",
    "    elif method == 'SFFS':\n",
    "        sfs = SFS(model,\n",
    "                  k_features=\"best\",\n",
    "                  forward=True,\n",
    "                  floating=True,\n",
    "                  verbose=2,\n",
    "                  scoring='accuracy',\n",
    "                  cv=cv,\n",
    "                  n_jobs=-1)\n",
    "    # Aplicando o método de seleção de features\n",
    "    sfs = sfs.fit(data, target)\n",
    "    # Salvando o resultado em um dataframe\n",
    "    df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "\n",
    "    # Definindo nome do arquivo para salvar as features selecionadas em formato CSV\n",
    "    if os.path.exists(f\"results/{method}_{best_model}.csv\"):\n",
    "        i = 1\n",
    "        while os.path.exists(f\"results/{method}_{best_model}_{i}.csv\"):\n",
    "            i += 1\n",
    "        file_name_csv = f\"results/{method}_{best_model}_{i}.csv\"\n",
    "    else:\n",
    "        file_name_csv = f\"results/{method}_{best_model}.csv\"\n",
    "\n",
    "    # Salvando o dataframe em um arquivo CSV\n",
    "    df.to_csv(file_name_csv, index=False)\n",
    "\n",
    "    # Definindo nome do arquivo para salvar as features selecionadas em formato TXT\n",
    "    if os.path.exists(f\"results/{method}_{best_model}.txt\"):\n",
    "        i = 1\n",
    "        while os.path.exists(f\"results/{method}_{best_model}_{i}.txt\"):\n",
    "            i += 1\n",
    "        file_name_txt = f\"results/{method}_{best_model}_{i}.txt\"\n",
    "    else:\n",
    "        file_name_txt = f\"results/{method}_{best_model}.txt\"\n",
    "\n",
    "    # Salvando as features selecionadas e o score em um arquivo TXT\n",
    "    with open(file_name_txt, 'w') as file:\n",
    "        file.write(f\"Selected Features: {', '.join(sfs.k_feature_names_)}\\n\")\n",
    "        file.write(f\"Score: {sfs.k_score_}\")\n",
    "\n",
    "    # Plotando o desempenho do modelo para cada combinação de atributos\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(range(1, len(df) + 1), df['avg_score'], marker='o')\n",
    "    ax.set_xlabel('Number of Features')\n",
    "    ax.set_ylabel('Average Score')\n",
    "    ax.set_title('Performance of Model with Feature Selection')\n",
    "    plt.xticks(range(1, len(df) + 1))\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Definindo nome do arquivo para salvar o gráfico\n",
    "    if os.path.exists(f\"results/{method}_{best_model}.png\"):\n",
    "        i = 1\n",
    "        while os.path.exists(f\"results/{method}_{best_model}_{i}.png\"):\n",
    "            i += 1\n",
    "        file_name_plot = f\"results/{method}_{best_model}_{i}.png\"\n",
    "    else:\n",
    "        file_name_plot = f\"results/{method}_{best_model}.png\"\n",
    "\n",
    "    # Salvando o gráfico em um arquivo PNG\n",
    "    plt.savefig(file_name_plot)\n",
    "\n",
    "    # Retornando as features selecionadas e o score\n",
    "    return sfs.k_feature_names_, sfs.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.615494715Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Função que muda max_features de auto p sqrt se tiver definido para evitar erro de versão\n",
    "def updt_maxfeature(modelo):\n",
    "    try:\n",
    "        if modelo.get_params()['max_features'] == 'auto':\n",
    "            modelo.max_features = 'sqrt'\n",
    "            print(modelo)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "updt_maxfeature(modelo1)\n",
    "updt_maxfeature(modelo2)\n",
    "updt_maxfeature(modelo3)\n",
    "updt_maxfeature(modelo4)\n",
    "updt_maxfeature(modelo5)\n",
    "updt_maxfeature(modelo6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.616362253Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chamando a função de feature selection para cada um dos \"modelos*\"\n",
    "print(\"========================== Data 1  =================================\")\n",
    "slt_sbfs_features1, score1_sbfs = perform_feature_selection(data1, target1, modelo1, \"data1\", 'SBFS', 5)\n",
    "slt_sffs_features1, score1_sffs = perform_feature_selection(data1, target1, modelo1, \"data1\", 'SFFS', 5)\n",
    "print(\"========================== Data 2  =================================\")\n",
    "slt_sbfs_features2, score2_sbfs = perform_feature_selection(data2, target2, modelo2, \"data2\", 'SBFS', 5)\n",
    "slt_sffs_features2, score2_sffs = perform_feature_selection(data2, target2, modelo2,\"data2\", 'SFFS', 5)\n",
    "print(\"========================== Data 3  =================================\")\n",
    "slt_sbfs_features3, score3_sbfs = perform_feature_selection(data3, target3, modelo3, \"data3\", 'SBFS', 5)\n",
    "slt_sffs_features3, score3_sffs = perform_feature_selection(data3, target3, modelo3, \"data3\", 'SFFS', 5)\n",
    "print(\"========================== Data 4  =================================\")\n",
    "slt_sbfs_features4, score4_sbfs = perform_feature_selection(data4, target4, modelo4,\"data4\", 'SBFS', 5)\n",
    "slt_sffs_features4, score4_sffs = perform_feature_selection(data4, target4, modelo4, \"data4\", 'SFFS', 5)\n",
    "print(\"========================== Data 5  =================================\")\n",
    "slt_sbfs_features5, score5_sbfs = perform_feature_selection(data5, target5, modelo5, \"data5\", 'SBFS', 5)\n",
    "slt_sffs_features5, score5_sffs = perform_feature_selection(data5, target5, modelo5, \"data5\", 'SFFS', 5)\n",
    "print(\"========================== Data 6  =================================\")\n",
    "slt_sbfs_features6, score6_sbfs = perform_feature_selection(data6, target6, modelo6, \"data6\", 'SBFS', 5)\n",
    "slt_sffs_features6, score6_sffs = perform_feature_selection(data6, target6, modelo6, \"data6\", 'SFFS', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.617176973Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criando um arquivo txt com a feature selecionadas\n",
    "with open(f\"results/SBFS_data1.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sbfs_features1))\n",
    "with open(f\"results/SFFS_data1.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sffs_features1))\n",
    "with open(f\"results/SBFS_data2.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sbfs_features2))\n",
    "with open(f\"results/SFFS_data2.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sffs_features2))\n",
    "with open(f\"results/SBFS_data3.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sbfs_features3))\n",
    "with open(f\"results/SFFS_data3.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sffs_features3))\n",
    "with open(f\"results/SBFS_data4.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sbfs_features4))\n",
    "with open(f\"results/SFFS_data4.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sffs_features4))\n",
    "with open(f\"results/SBFS_data5.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sbfs_features5))\n",
    "with open(f\"results/SFFS_data5.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sffs_features5))\n",
    "with open(f\"results/SBFS_data6.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sbfs_features6))\n",
    "with open(f\"results/SFFS_data6.txt\", \"w\") as f:\n",
    "    f.write(str(slt_sffs_features6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.618105274Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ler_arquivo_txt(nome_arquivo):\n",
    "    with open(nome_arquivo, 'r') as arquivo:\n",
    "        vetor_strings = []\n",
    "        for linha in arquivo:\n",
    "            valores = linha.strip().replace('(', '').replace(')', '').replace(\"'\", '').split(', ')\n",
    "            vetor_strings.append(valores)\n",
    "    return vetor_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.618798637Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lendo os arquivos txt com as features selecionadas\n",
    "slt_sbfs_features1 = ler_arquivo_txt('results/SBFS_data1.txt')[0]\n",
    "slt_sffs_features1 = ler_arquivo_txt('results/SFFS_data1.txt')[0]\n",
    "slt_sbfs_features2 = ler_arquivo_txt('results/SBFS_data2.txt')[0]\n",
    "slt_sffs_features2 = ler_arquivo_txt('results/SFFS_data2.txt')[0]\n",
    "slt_sbfs_features3 = ler_arquivo_txt('results/SBFS_data3.txt')[0]\n",
    "slt_sffs_features3 = ler_arquivo_txt('results/SFFS_data3.txt')[0]\n",
    "slt_sbfs_features4 = ler_arquivo_txt('results/SBFS_data4.txt')[0]\n",
    "slt_sffs_features4 = ler_arquivo_txt('results/SFFS_data4.txt')[0]\n",
    "slt_sbfs_features5 = ler_arquivo_txt('results/SBFS_data5.txt')[0]\n",
    "slt_sffs_features5 = ler_arquivo_txt('results/SFFS_data5.txt')[0]\n",
    "slt_sbfs_features6 = ler_arquivo_txt('results/SBFS_data6.txt')[0]\n",
    "slt_sffs_features6 = ler_arquivo_txt('results/SFFS_data6.txt')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.619556621Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testando os modelos com as features selecionadas\n",
    "print(\"========================== Data 1  - SBFS =================================\")\n",
    "perform_cross_validation(modelo1, data1_re.loc[:,slt_sbfs_features1], target1_re, 5, False)\n",
    "\n",
    "print(\"========================== Data 1  - SFFS =================================\")\n",
    "perform_cross_validation(modelo1, data1_re.loc[:,slt_sffs_features1], target1_re, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.620973263Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"========================== Data 2  - SBFS =================================\")\n",
    "perform_cross_validation(modelo2, data2_re.loc[:,slt_sbfs_features2], target2_re, 5, False)\n",
    "\n",
    "print(\"========================== Data 2  - SFFS =================================\")\n",
    "perform_cross_validation(modelo2, data2_re.loc[:,slt_sffs_features2], target2_re, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.621570056Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"========================== Data 3  - SBFS =================================\")\n",
    "perform_cross_validation(modelo3, data3_re.loc[:,slt_sbfs_features3], target3_re, 5, False)\n",
    "\n",
    "print(\"========================== Data 3  - SFFS =================================\")\n",
    "perform_cross_validation(modelo3, data3_re.loc[:,slt_sffs_features3], target3_re, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.622276072Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"========================== Data 4  - SBFS =================================\")\n",
    "perform_cross_validation(modelo4, data4_re.loc[:,slt_sbfs_features4], target4_re, 5, False)\n",
    "\n",
    "print(\"========================== Data 4  - SFFS =================================\")\n",
    "perform_cross_validation(modelo4, data4_re.loc[:,slt_sffs_features4], target4_re, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.622904945Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"========================== Data 5  - SBFS =================================\")\n",
    "perform_cross_validation(modelo5, data5_re.loc[:,slt_sbfs_features5], target5_re, 5, False)\n",
    "\n",
    "print(\"========================== Data 5  - SFFS =================================\")\n",
    "perform_cross_validation(modelo5, data5_re.loc[:,slt_sffs_features5], target5_re, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.623463907Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"========================== Data 6  - SBFS =================================\")\n",
    "perform_cross_validation(modelo6, data6_re.loc[:,slt_sbfs_features6], target6_re, 5, False)\n",
    "\n",
    "print(\"========================== Data 6  - SFFS =================================\")\n",
    "perform_cross_validation(modelo6, data6_re.loc[:,slt_sffs_features6], target6_re, 5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.623956035Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#print(\"========================== Data 1  =================================\")\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data1, target1, test_size=0.2)\n",
    "#tpot = TPOTClassifier(verbosity=2, config_dict='TPOT light')\n",
    "#tpot.fit(X_train, y_train)\n",
    "#accuracy = tpot.score(X_test, y_test)\n",
    "#print(f\"Acurácia do melhor modelo encontrado: {accuracy}\")\n",
    "#tpot.export('tpot_best_model1.py')\n",
    "#print(\"========================== Data 2  =================================\")\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data2, target2, test_size=0.2)\n",
    "#tpot2 = TPOTClassifier(verbosity=2, config_dict='TPOT light')\n",
    "#tpot2.fit(X_train, y_train)\n",
    "#accuracy = tpot2.score(X_test, y_test)\n",
    "#print(f\"Acurácia do melhor modelo encontrado: {accuracy}\")\n",
    "##tpot2.export('tpot_best_model2.py')\n",
    "#print(\"========================== Data 3  =================================\")\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data3, target3, test_size=0.2)\n",
    "#tpot3 = TPOTClassifier(verbosity=2, config_dict='TPOT light')\n",
    "#tpot3.fit(X_train, y_train)\n",
    "#accuracy = tpot3.score(X_test, y_test)\n",
    "#print(f\"Acurácia do melhor modelo encontrado: {accuracy}\")\n",
    "#tpot3.export('tpot_best_model3.py')\n",
    "#print(\"========================== Data 4  =================================\")\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data4, target4, test_size=0.2)\n",
    "#$tpot4 = TPOTClassifier(verbosity=2,config_dict='TPOT light')\n",
    "#tpot4.fit(X_train, y_train)\n",
    "#accuracy = tpot4.score(X_test, y_test)\n",
    "#print(f\"Acurácia do melhor modelo encontrado: {accuracy}\")\n",
    "#tpot4.export('tpot_best_model4.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-17T00:53:08.624410843Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Definindo as classes\n",
    "classes = [\"Baixo\", \"Médio\", \"Alto\"]\n",
    "\n",
    "# Sua matriz de confusão de três classes\n",
    "conf_matrix = np.array([[20, 0, 2],\n",
    "                        [0, 30, 1],\n",
    "                        [12, 3, 27]])\n",
    "\n",
    "# Calculando precisão, recall e f1 score para cada classe\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for i in range(len(conf_matrix)):\n",
    "    TP = conf_matrix[i][i]\n",
    "    FP = sum(conf_matrix[r][i] for r in range(len(conf_matrix)) if r != i)\n",
    "    FN = sum(conf_matrix[i][c] for c in range(len(conf_matrix)) if c != i)\n",
    "\n",
    "    precision.append(TP / (TP + FP))\n",
    "    recall.append(TP / (TP + FN))\n",
    "    f1.append(2 * (precision[i] * recall[i]) / (precision[i] + recall[i]))\n",
    "\n",
    "# Criando um DataFrame com os resultados\n",
    "df = pd.DataFrame({'Classe': classes, 'Precisão': precision, 'Recall': recall, 'F1 Score': f1})\n",
    "\n",
    "# Plotando a matriz de confusão\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", xticklabels=classes, yticklabels=classes, annot_kws={\"size\": 14})\n",
    "plt.xlabel('Classe Prevista', size=12, fontweight='bold')\n",
    "plt.ylabel('Classe Real', size=12, fontweight='bold')\n",
    "plt.title('Matriz de Confusão - SBFS - DATA 2', size=14, fontweight='bold')\n",
    "plt.savefig('confusion_matrix_sbfs_data2.png', dpi=300, transparent=True)\n",
    "plt.show()\n",
    "\n",
    "# Exibindo a tabela com os resultados\n",
    "print(\"Tabela de Resultados:\")\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
