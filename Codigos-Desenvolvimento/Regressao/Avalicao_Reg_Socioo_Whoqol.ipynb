{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:40:12.116574400Z",
     "start_time": "2023-05-18T16:40:12.104796100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "# r2\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#Importando modelos de machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:40:15.699035100Z",
     "start_time": "2023-05-18T16:40:15.671858200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importando base de dados que contem o header\n",
    "base = pd.read_csv('/home/apo-note/Documents/GitHub/Classificacao_MHI_BIC/Codigos-Desenvolvimento/Datasets/df_soc_whoqol_reg.csv')\n",
    "# Dividindo entre X e y, pelo tamanho da base\n",
    "X = base.drop('Nivel_MHI', axis=1)\n",
    "X = X.drop('MHI_Score', axis=1)\n",
    "y = base['MHI_Score'].apply(lambda x: x/100)\n",
    "\n",
    "df_Niveis = base['Nivel_MHI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:40:16.188359600Z",
     "start_time": "2023-05-18T16:40:16.169975200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    872.000000\n",
       "mean       1.385585\n",
       "std        0.335148\n",
       "min        0.470000\n",
       "25%        1.170000\n",
       "50%        1.390000\n",
       "75%        1.640000\n",
       "max        2.240000\n",
       "Name: MHI_Score, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T16:40:16.703286900Z",
     "start_time": "2023-05-18T16:40:16.674439300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dividindo a base entre treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import math\n",
    "import time\n",
    "\n",
    "def test_and_tune_regression_models(x_train, y_train, x_test, y_test, filename='regression_results.csv'):\n",
    "  \"\"\"\n",
    "  Tests various regression models, displays results, performs Random Search\n",
    "  for hyperparameter tuning, and presents the tuned results.\n",
    "\n",
    "  Args:\n",
    "      x_train (pandas.DataFrame): Training data features.\n",
    "      y_train (pandas.Series): Training data target variable.\n",
    "      x_test (pandas.DataFrame): Testing data features.\n",
    "      y_test (pandas.Series): Testing data target variable.\n",
    "      filename (str): Name of the CSV file to save results to.\n",
    "\n",
    "  Returns:\n",
    "      None\n",
    "  \n",
    "  Outputs:\n",
    "      CSV file: A CSV file containing the results of the regression models.\n",
    "  \"\"\"\n",
    "\n",
    "  # Define models and their parameter grids for random search\n",
    "  models = {\n",
    "      'Linear Regression': {\n",
    "          'model': LinearRegression(),\n",
    "          'param_grid': {}  # Linear Regression has no hyperparameters to tune\n",
    "      },\n",
    "      'Decision Tree': {\n",
    "          'model': DecisionTreeRegressor(),\n",
    "          'param_grid': {\n",
    "            #   'max_depth': range(2, 10),\n",
    "            #   'min_samples_split': range(2, 20),\n",
    "            #   'min_samples_leaf': range(1, 10)\n",
    "                'criterion': ['absolute_error', 'squared_error', 'friedman_mse', 'poisson'],\n",
    "                'splitter': ['best', 'random'],\n",
    "                'max_depth': np.unique(np.linspace(math.log2(len(np.unique(y))), len(X.columns) // 2, 20, dtype=int)),\n",
    "                'min_samples_split': np.linspace(0.01, 1, 20),\n",
    "                'min_samples_leaf': np.linspace(0.01, 0.5, 20)\n",
    "          }\n",
    "      },\n",
    "      'Random Forest': {\n",
    "          'model': RandomForestRegressor(n_jobs=-1),\n",
    "          'param_grid': {\n",
    "            #   'n_estimators': range(100, 1000, 100),\n",
    "            #   'max_depth': range(2, 10),\n",
    "            #   'min_samples_split': range(2, 20),\n",
    "            #   'min_samples_leaf': range(1, 10)\n",
    "                # Vetor linear inteiro, entre log2(numero_de_classes) e numero_de_features/2\n",
    "                'max_depth': np.unique(np.linspace(math.log2(len(np.unique(y))), len(X.columns) // 2, 20, dtype=int)),\n",
    "                # Vetor linear inteiro, de ln(numero de objetos no conjunto) -40 até ln(numero de objetos no conjunto) + 45\n",
    "                'n_estimators': np.unique(np.maximum(np.linspace(math.log(len(X)) - 40, math.log(len(X)) + 45, 20, dtype=int),1)),\n",
    "                # Vetor linear inteiro, numero features * 0.3 até numero features * 0.8\n",
    "                'max_features': np.unique(np.linspace(int(len(X.columns) * 0.3), int(len(X.columns) * 0.8), 20, dtype=int)),\n",
    "                'criterion': ['absolute_error', 'squared_error', 'friedman_mse', 'poisson'],\n",
    "                'bootstrap': [True, False]\n",
    "          }\n",
    "      },\n",
    "      'XGBoost': {\n",
    "          'model': XGBRegressor(n_jobs=-1),\n",
    "          'param_grid': {\n",
    "              'n_estimators': range(100, 1000, 100),\n",
    "              'learning_rate': [0.01, 0.1, 1],\n",
    "              'max_depth': range(2, 10),\n",
    "              'min_child_weight': range(1, 10),\n",
    "              'gamma': [0, 0.1, 1]\n",
    "          }\n",
    "      },\n",
    "      'K-Nearest Neighbors': {\n",
    "          'model': KNeighborsRegressor(n_jobs=-1),\n",
    "          'param_grid': {\n",
    "                'n_neighbors': np.linspace(1, 30, 15, dtype=int),\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                'p': [1, 2, 3, 4],\n",
    "                'leaf_size': np.linspace(1, 100, 20, dtype=int)\n",
    "          }\n",
    "      },\n",
    "      'Multi-Layer Perceptron (Neural Network)': {\n",
    "          'model': MLPRegressor(),\n",
    "          'param_grid': {\n",
    "            #   'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "                'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                'hidden_layer_sizes': [(neurons,) * layers for layers in range(1, 4) for neurons in range(len(X.columns) * 5, len(X.columns) * 10 + 1)],\n",
    "                'learning_rate_init': np.linspace(0.0001, 1, 10),\n",
    "                'momentum': np.linspace(0.1, 0.9, 10),\n",
    "                'max_iter': np.linspace(400, 4000, 20, dtype=int)\n",
    "          }\n",
    "      },\n",
    "      'Support Vector Regression (SVR)': {\n",
    "          'model': SVR(),\n",
    "          'param_grid': {\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'C': [0.00001, 0.0001, 0.001,  0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "            # 'degree': [3, 5, 8],\n",
    "            'coef0': [0.01, 10, 0.5],\n",
    "            'gamma': ['auto', 'scale']\n",
    "            }\n",
    "      }\n",
    "\n",
    "}\n",
    "\n",
    "  # Prepare empty DataFrame to store results\n",
    "  results = pd.DataFrame(columns=['Modelo', 'Pre-Tuning MSE', 'Pre-Tuning RMSE', 'Pre-Tuning R2', 'Pre-Tuning R2 Ajustado', 'Pos-Tuning MSE', 'Pos-Tuning RMSE', 'Pos-Tuning R2', 'Pos-Tuning R2 Ajustado' 'Melhores Parametros'])\n",
    "\n",
    "  # Test each model, store results, and print\n",
    "  for model_name, model_info in models.items():\n",
    "    model = model_info['model']\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Update results DataFrame\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        'Modelo': [model_name],\n",
    "        'Pre-Tuning MSE': [mse],\n",
    "        'Pre-Tuning RMSE': [rmse],\n",
    "        'Pre-Tuning R2': [r2],\n",
    "        'Pre-Tuning R2 Ajustado': [1 - (1 - r2) * (len(y_test) - 1) / (len(y_test) - len(X.columns) - 1)], # Adjusted R2 = 1 - (1 - R2) * (n - 1) / (n - p - 1)\n",
    "        'Pos-Tuning MSE': [None],\n",
    "        'Pos-Tuning RMSE': [None],\n",
    "        'Pos-Tuning R2': [None],\n",
    "        'Pos-Tuning R2 Ajustado': [None],\n",
    "        'Melhores Parametros': [None]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    print(f\"\\n\\n**{model_name} Resultados (Antes do Tuning):**\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "    print(f\"R2 Ajustado: {1 - (1 - r2) * (len(y_test) - 1) / (len(y_test) - len(X.columns) - 1):.4f}\")\n",
    "\n",
    "    print(f'\\n_Realizando Tuning do Modelo: {model_name}_')\n",
    "    agora = time.time()\n",
    "    param_grid = model_info['param_grid']\n",
    "    random_search = RandomizedSearchCV(model, param_grid, n_iter=25, cv=2, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "    if model_name == 'Support Vector Regression (SVR)': # Use only a subset of the data for SVR to speed up tuning\n",
    "        print(\"Usando subset\")\n",
    "        x_train_subset, _, y_train_subset, _ = train_test_split(x_train, y_train, train_size=0.3, shuffle=True)\n",
    "        random_search.fit(x_train_subset, y_train_subset)\n",
    "    else:\n",
    "        random_search.fit(x_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_ajustado = 1 - (1 - r2) * (len(y_test) - 1) / (len(y_test) - len(X.columns) - 1)\n",
    "    depois = time.time()\n",
    "\n",
    "    print(f\"Tempo de execução: {depois - agora:.2f} segundos.\")\n",
    "\n",
    "    # Update results DataFrame\n",
    "    results.loc[results['Modelo'] == model_name, 'Pos-Tuning MSE'] = mse\n",
    "    results.loc[results['Modelo'] == model_name, 'Pos-Tuning RMSE'] = rmse\n",
    "    results.loc[results['Modelo'] == model_name, 'Pos-Tuning R2'] = r2\n",
    "    results.loc[results['Modelo'] == model_name, 'Pos-Tuning R2 Ajustado'] = r2_ajustado\n",
    "    results.loc[results['Modelo'] == model_name, 'Melhores Parametros'] = random_search.best_params_\n",
    "\n",
    "    print(f\"**{model_name} Resultados (Depois do Tuning):**\")\n",
    "    print(f\"Melhores Parametros: {random_search.best_params_}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "    print(f\"R2 Ajustado: {r2_ajustado:.4f}\")\n",
    "\n",
    "  # Save results to CSV file\n",
    "  results.to_csv(filename, index=False)\n",
    "\n",
    "  print(f\"\\nResultados salvos em: '{filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**Linear Regression Resultados (Antes do Tuning):**\n",
      "MSE: 0.0306\n",
      "RMSE: 0.1750\n",
      "R2: 0.7262\n",
      "\n",
      "_Realizando Tuning do Modelo: Linear Regression_\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_411826/250377636.py:129: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame({\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_search.py:318: UserWarning: The total space of parameters 1 is smaller than n_iter=25. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "Tempo de execução: 0.98 segundos.\n",
      "**Linear Regression Resultados (Depois do Tuning):**\n",
      "Melhores Parametros: {}\n",
      "MSE: 0.0306\n",
      "RMSE: 0.1750\n",
      "R2: 0.7262\n",
      "\n",
      "\n",
      "**Decision Tree Resultados (Antes do Tuning):**\n",
      "MSE: 0.0768\n",
      "RMSE: 0.2772\n",
      "R2: 0.3129\n",
      "\n",
      "_Realizando Tuning do Modelo: Decision Tree_\n",
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
      "[CV] END criterion=poisson, max_depth=34, min_samples_leaf=0.08736842105263157, min_samples_split=0.8436842105263158, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=poisson, max_depth=25, min_samples_leaf=0.44842105263157894, min_samples_split=0.8436842105263158, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=poisson, max_depth=25, min_samples_leaf=0.44842105263157894, min_samples_split=0.8436842105263158, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=poisson, max_depth=42, min_samples_leaf=0.47421052631578947, min_samples_split=0.7394736842105263, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=poisson, max_depth=42, min_samples_leaf=0.47421052631578947, min_samples_split=0.7394736842105263, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=34, min_samples_leaf=0.16473684210526315, min_samples_split=0.5310526315789474, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=poisson, max_depth=34, min_samples_leaf=0.08736842105263157, min_samples_split=0.8436842105263158, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=34, min_samples_leaf=0.16473684210526315, min_samples_split=0.5310526315789474, splitter=best; total time=   0.0s[CV] END criterion=friedman_mse, max_depth=34, min_samples_leaf=0.37105263157894736, min_samples_split=0.4789473684210527, splitter=random; total time=   0.0s\n",
      "\n",
      "[CV] END criterion=friedman_mse, max_depth=34, min_samples_leaf=0.37105263157894736, min_samples_split=0.4789473684210527, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=42, min_samples_leaf=0.5, min_samples_split=0.37473684210526315, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=42, min_samples_leaf=0.5, min_samples_split=0.37473684210526315, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=10, min_samples_leaf=0.29368421052631577, min_samples_split=0.8436842105263158, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=10, min_samples_leaf=0.29368421052631577, min_samples_split=0.8436842105263158, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=7, min_samples_leaf=0.2163157894736842, min_samples_split=0.16631578947368422, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=poisson, max_depth=18, min_samples_leaf=0.01, min_samples_split=0.5310526315789474, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=poisson, max_depth=18, min_samples_leaf=0.01, min_samples_split=0.5310526315789474, splitter=best; total time=   0.0s[CV] END criterion=absolute_error, max_depth=7, min_samples_leaf=0.2163157894736842, min_samples_split=0.16631578947368422, splitter=random; total time=   0.0s\n",
      "\n",
      "[CV] END criterion=squared_error, max_depth=10, min_samples_leaf=0.13894736842105262, min_samples_split=0.6352631578947369, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=18, min_samples_leaf=0.035789473684210524, min_samples_split=0.6873684210526316, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=10, min_samples_leaf=0.13894736842105262, min_samples_split=0.6352631578947369, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=18, min_samples_leaf=0.035789473684210524, min_samples_split=0.6873684210526316, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=16, min_samples_leaf=0.08736842105263157, min_samples_split=0.7394736842105263, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=16, min_samples_leaf=0.08736842105263157, min_samples_split=0.7394736842105263, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=40, min_samples_leaf=0.37105263157894736, min_samples_split=0.2705263157894737, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=12, min_samples_leaf=0.16473684210526315, min_samples_split=0.5310526315789474, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=40, min_samples_leaf=0.37105263157894736, min_samples_split=0.2705263157894737, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=40, min_samples_leaf=0.44842105263157894, min_samples_split=0.5831578947368421, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=40, min_samples_leaf=0.44842105263157894, min_samples_split=0.5831578947368421, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=12, min_samples_leaf=0.16473684210526315, min_samples_split=0.5310526315789474, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=9, min_samples_leaf=0.035789473684210524, min_samples_split=0.5310526315789474, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=9, min_samples_leaf=0.035789473684210524, min_samples_split=0.5310526315789474, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=poisson, max_depth=12, min_samples_leaf=0.16473684210526315, min_samples_split=0.37473684210526315, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=poisson, max_depth=12, min_samples_leaf=0.16473684210526315, min_samples_split=0.37473684210526315, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=18, min_samples_leaf=0.44842105263157894, min_samples_split=0.32263157894736844, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=18, min_samples_leaf=0.44842105263157894, min_samples_split=0.32263157894736844, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=38, min_samples_leaf=0.3194736842105263, min_samples_split=0.16631578947368422, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=38, min_samples_leaf=0.3194736842105263, min_samples_split=0.16631578947368422, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=20, min_samples_leaf=0.44842105263157894, min_samples_split=0.7394736842105263, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=20, min_samples_leaf=0.44842105263157894, min_samples_split=0.7394736842105263, splitter=best; total time=   0.0s[CV] END criterion=absolute_error, max_depth=40, min_samples_leaf=0.24210526315789474, min_samples_split=0.4268421052631579, splitter=random; total time=   0.0s\n",
      "\n",
      "[CV] END criterion=friedman_mse, max_depth=40, min_samples_leaf=0.29368421052631577, min_samples_split=0.6873684210526316, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, max_depth=40, min_samples_leaf=0.29368421052631577, min_samples_split=0.6873684210526316, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=absolute_error, max_depth=40, min_samples_leaf=0.24210526315789474, min_samples_split=0.4268421052631579, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=42, min_samples_leaf=0.3452631578947368, min_samples_split=0.21842105263157896, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=21, min_samples_leaf=0.4226315789473684, min_samples_split=0.791578947368421, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=21, min_samples_leaf=0.4226315789473684, min_samples_split=0.791578947368421, splitter=best; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=38, min_samples_leaf=0.44842105263157894, min_samples_split=0.8957894736842106, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=38, min_samples_leaf=0.44842105263157894, min_samples_split=0.8957894736842106, splitter=random; total time=   0.0s\n",
      "[CV] END criterion=squared_error, max_depth=42, min_samples_leaf=0.3452631578947368, min_samples_split=0.21842105263157896, splitter=best; total time=   0.0s\n",
      "Tempo de execução: 1.31 segundos.\n",
      "**Decision Tree Resultados (Depois do Tuning):**\n",
      "Melhores Parametros: {'splitter': 'best', 'min_samples_split': 0.5310526315789474, 'min_samples_leaf': 0.16473684210526315, 'max_depth': 34, 'criterion': 'squared_error'}\n",
      "MSE: 0.0576\n",
      "RMSE: 0.2399\n",
      "R2: 0.4852\n",
      "\n",
      "\n",
      "**Random Forest Resultados (Antes do Tuning):**\n",
      "MSE: 0.0346\n",
      "RMSE: 0.1861\n",
      "R2: 0.6902\n",
      "\n",
      "_Realizando Tuning do Modelo: Random Forest_\n",
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=23, max_features=53, n_estimators=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=23, max_features=53, n_estimators=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=32, max_features=25, n_estimators=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=31, max_features=64, n_estimators=7; total time=   0.2s[CV] END bootstrap=True, criterion=poisson, max_depth=32, max_features=25, n_estimators=2; total time=   0.1s\n",
      "\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=31, max_features=64, n_estimators=7; total time=   0.2s[CV] END bootstrap=False, criterion=squared_error, max_depth=29, max_features=60, n_estimators=33; total time=   0.2s\n",
      "\n",
      "[CV] END bootstrap=False, criterion=squared_error, max_depth=29, max_features=60, n_estimators=33; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=31, max_features=67, n_estimators=29; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=27, max_features=62, n_estimators=24; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=27, max_features=62, n_estimators=24; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=44, n_estimators=38; total time=   0.3s[CV] END bootstrap=False, criterion=poisson, max_depth=31, max_features=67, n_estimators=29; total time=   0.3s\n",
      "\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=44, n_estimators=38; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=squared_error, max_depth=32, max_features=44, n_estimators=38; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=squared_error, max_depth=32, max_features=44, n_estimators=38; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=44, n_estimators=20; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=squared_error, max_depth=31, max_features=58, n_estimators=11; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=squared_error, max_depth=42, max_features=55, n_estimators=24; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=40, n_estimators=7; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=29, max_features=58, n_estimators=11; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=42, max_features=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=23, max_features=33, n_estimators=51; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=squared_error, max_depth=31, max_features=58, n_estimators=11; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=44, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=squared_error, max_depth=42, max_features=55, n_estimators=24; total time=   0.3s[CV] END bootstrap=False, criterion=poisson, max_depth=29, max_features=58, n_estimators=11; total time=   0.2s\n",
      "\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=40, n_estimators=7; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=squared_error, max_depth=38, max_features=49, n_estimators=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=53, n_estimators=20; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=42, max_features=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=36, max_features=40, n_estimators=15; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=squared_error, max_depth=38, max_features=49, n_estimators=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=18, max_features=33, n_estimators=38; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=29, max_features=64, n_estimators=15; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=60, n_estimators=11; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=23, max_features=33, n_estimators=51; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=squared_error, max_depth=12, max_features=27, n_estimators=33; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=36, max_features=40, n_estimators=15; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=27, n_estimators=29; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=18, max_features=33, n_estimators=38; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=60, n_estimators=11; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=53, n_estimators=20; total time=   0.3s[CV] END bootstrap=False, criterion=poisson, max_depth=29, max_features=64, n_estimators=15; total time=   0.2s\n",
      "\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=16, max_features=44, n_estimators=1; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=16, max_features=44, n_estimators=1; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=27, n_estimators=29; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=squared_error, max_depth=12, max_features=27, n_estimators=33; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=29, n_estimators=38; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=29, n_estimators=38; total time=   0.1s\n",
      "Tempo de execução: 1.64 segundos.\n",
      "**Random Forest Resultados (Depois do Tuning):**\n",
      "Melhores Parametros: {'n_estimators': 38, 'max_features': 33, 'max_depth': 18, 'criterion': 'friedman_mse', 'bootstrap': True}\n",
      "MSE: 0.0330\n",
      "RMSE: 0.1817\n",
      "R2: 0.7047\n",
      "\n",
      "\n",
      "**XGBoost Resultados (Antes do Tuning):**\n",
      "MSE: 0.0389\n",
      "RMSE: 0.1971\n",
      "R2: 0.6525\n",
      "\n",
      "_Realizando Tuning do Modelo: XGBoost_\n",
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=8, min_child_weight=8, n_estimators=500; total time=   0.1s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=8, min_child_weight=8, n_estimators=500; total time=   0.1s\n",
      "[CV] END gamma=1, learning_rate=1, max_depth=2, min_child_weight=9, n_estimators=900; total time=   0.2s\n",
      "[CV] END gamma=1, learning_rate=1, max_depth=2, min_child_weight=9, n_estimators=900; total time=   0.2s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=9, min_child_weight=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END gamma=1, learning_rate=1, max_depth=5, min_child_weight=3, n_estimators=600; total time=   0.1s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=9, min_child_weight=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END gamma=1, learning_rate=1, max_depth=5, min_child_weight=3, n_estimators=600; total time=   0.2s\n",
      "[CV] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END gamma=0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=800; total time=   0.2s\n",
      "[CV] END gamma=0, learning_rate=0.01, max_depth=2, min_child_weight=4, n_estimators=800; total time=   0.3s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=9, n_estimators=200; total time=   0.1s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=2, min_child_weight=9, n_estimators=400; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=1, max_depth=8, min_child_weight=2, n_estimators=700; total time=   0.2s\n",
      "[CV] END gamma=0, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=300; total time=   0.5s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=9, n_estimators=200; total time=   0.1s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=2, min_child_weight=9, n_estimators=400; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=1, max_depth=6, min_child_weight=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END gamma=0, learning_rate=0.01, max_depth=7, min_child_weight=3, n_estimators=300; total time=   0.6s\n",
      "[CV] END gamma=0.1, learning_rate=1, max_depth=8, min_child_weight=2, n_estimators=700; total time=   0.2s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=700; total time=   0.2s\n",
      "[CV] END gamma=1, learning_rate=1, max_depth=3, min_child_weight=7, n_estimators=800; total time=   0.2s\n",
      "[CV] END gamma=0.1, learning_rate=1, max_depth=6, min_child_weight=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END gamma=0, learning_rate=0.1, max_depth=6, min_child_weight=7, n_estimators=900; total time=   0.4s\n",
      "[CV] END gamma=1, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=400; total time=   0.1s\n",
      "[CV] END gamma=0, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=800; total time=   0.4s\n",
      "[CV] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=7, n_estimators=400; total time=   0.2s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=700; total time=   0.2s\n",
      "[CV] END gamma=1, learning_rate=1, max_depth=3, min_child_weight=7, n_estimators=800; total time=   0.2s\n",
      "[CV] END gamma=1, learning_rate=0.01, max_depth=4, min_child_weight=6, n_estimators=400; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=2, min_child_weight=3, n_estimators=500; total time=   0.1s\n",
      "[CV] END gamma=1, learning_rate=1, max_depth=6, min_child_weight=1, n_estimators=800; total time=   0.2s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=9, n_estimators=400; total time=   0.1s[CV] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=7, n_estimators=400; total time=   0.2s\n",
      "\n",
      "[CV] END gamma=0.1, learning_rate=0.01, max_depth=8, min_child_weight=1, n_estimators=700; total time=   0.4s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=4, n_estimators=600; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=2, min_child_weight=3, n_estimators=500; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=300; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=9, n_estimators=400; total time=   0.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=300; total time=   0.1s\n",
      "[CV] END gamma=1, learning_rate=1, max_depth=6, min_child_weight=1, n_estimators=800; total time=   0.2s\n",
      "[CV] END gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=4, n_estimators=600; total time=   0.1s\n",
      "[CV] END gamma=0, learning_rate=0.1, max_depth=6, min_child_weight=7, n_estimators=900; total time=   0.4s\n",
      "[CV] END gamma=0, learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=800; total time=   0.4s\n",
      "[CV] END gamma=0.1, learning_rate=0.01, max_depth=8, min_child_weight=1, n_estimators=700; total time=   0.2s\n",
      "Tempo de execução: 1.40 segundos.\n",
      "**XGBoost Resultados (Depois do Tuning):**\n",
      "Melhores Parametros: {'n_estimators': 800, 'min_child_weight': 4, 'max_depth': 2, 'learning_rate': 0.01, 'gamma': 0}\n",
      "MSE: 0.0316\n",
      "RMSE: 0.1777\n",
      "R2: 0.7175\n",
      "\n",
      "\n",
      "**K-Nearest Neighbors Resultados (Antes do Tuning):**\n",
      "MSE: 0.0469\n",
      "RMSE: 0.2165\n",
      "R2: 0.5809\n",
      "\n",
      "_Realizando Tuning do Modelo: K-Nearest Neighbors_\n",
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
      "[CV] END algorithm=auto, leaf_size=94, n_neighbors=30, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, leaf_size=94, n_neighbors=30, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=auto, leaf_size=73, n_neighbors=1, p=2, weights=uniform; total time=   0.0s[CV] END algorithm=auto, leaf_size=73, n_neighbors=1, p=2, weights=uniform; total time=   0.0s\n",
      "\n",
      "[CV] END algorithm=brute, leaf_size=16, n_neighbors=30, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=16, n_neighbors=30, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=79, n_neighbors=15, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=79, n_neighbors=15, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=94, n_neighbors=5, p=4, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=94, n_neighbors=5, p=4, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=brute, leaf_size=58, n_neighbors=15, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=58, n_neighbors=15, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=84, n_neighbors=13, p=3, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=brute, leaf_size=84, n_neighbors=13, p=3, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=53, n_neighbors=27, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=53, n_neighbors=27, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=63, n_neighbors=23, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=42, n_neighbors=11, p=3, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, leaf_size=63, n_neighbors=23, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=42, n_neighbors=11, p=3, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=auto, leaf_size=37, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=37, n_neighbors=11, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=42, n_neighbors=17, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=1, n_neighbors=9, p=4, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=1, n_neighbors=9, p=4, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=brute, leaf_size=94, n_neighbors=21, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=73, n_neighbors=19, p=3, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=auto, leaf_size=73, n_neighbors=21, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=94, n_neighbors=21, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=73, n_neighbors=21, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=42, n_neighbors=17, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=68, n_neighbors=25, p=3, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=brute, leaf_size=6, n_neighbors=1, p=3, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=brute, leaf_size=94, n_neighbors=17, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, n_neighbors=30, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=100, n_neighbors=30, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=94, n_neighbors=17, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=37, n_neighbors=17, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, leaf_size=37, n_neighbors=17, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=16, n_neighbors=30, p=3, weights=distance; total time=   0.3s\n",
      "[CV] END algorithm=brute, leaf_size=47, n_neighbors=1, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=47, n_neighbors=1, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=84, n_neighbors=7, p=3, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=68, n_neighbors=25, p=3, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=auto, leaf_size=16, n_neighbors=13, p=3, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, leaf_size=84, n_neighbors=7, p=3, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=6, n_neighbors=1, p=3, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=brute, leaf_size=73, n_neighbors=19, p=3, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=auto, leaf_size=16, n_neighbors=30, p=3, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=auto, leaf_size=16, n_neighbors=13, p=3, weights=uniform; total time=   0.1s\n",
      "Tempo de execução: 1.00 segundos.\n",
      "**K-Nearest Neighbors Resultados (Depois do Tuning):**\n",
      "Melhores Parametros: {'weights': 'distance', 'p': 1, 'n_neighbors': 27, 'leaf_size': 53, 'algorithm': 'auto'}\n",
      "MSE: 0.0428\n",
      "RMSE: 0.2068\n",
      "R2: 0.6174\n",
      "\n",
      "\n",
      "**Multi-Layer Perceptron (Neural Network) Resultados (Antes do Tuning):**\n",
      "MSE: 0.1278\n",
      "RMSE: 0.3575\n",
      "R2: -0.1430\n",
      "\n",
      "_Realizando Tuning do Modelo: Multi-Layer Perceptron (Neural Network)_\n",
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, hidden_layer_sizes=(722, 722), learning_rate_init=0.8889, max_iter=1536, momentum=0.7222222222222222, solver=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(722, 722), learning_rate_init=0.8889, max_iter=1536, momentum=0.7222222222222222, solver=sgd; total time=   3.7s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(423, 423, 423), learning_rate_init=0.6667000000000001, max_iter=3052, momentum=0.1, solver=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(423, 423, 423), learning_rate_init=0.6667000000000001, max_iter=3052, momentum=0.1, solver=adam; total time=   3.2s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(835,), learning_rate_init=0.2223, max_iter=3810, momentum=0.2777777777777778, solver=adam; total time=   6.9s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(795,), learning_rate_init=0.2223, max_iter=3052, momentum=0.2777777777777778, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(795,), learning_rate_init=0.2223, max_iter=3052, momentum=0.2777777777777778, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(835,), learning_rate_init=0.2223, max_iter=3810, momentum=0.2777777777777778, solver=adam; total time=   9.2s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(689, 689, 689), learning_rate_init=1.0, max_iter=4000, momentum=0.18888888888888888, solver=lbfgs; total time=  24.5s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(553,), learning_rate_init=0.2223, max_iter=3242, momentum=0.8111111111111111, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(553,), learning_rate_init=0.2223, max_iter=3242, momentum=0.8111111111111111, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(689, 689, 689), learning_rate_init=1.0, max_iter=4000, momentum=0.18888888888888888, solver=lbfgs; total time=  25.6s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(455, 455), learning_rate_init=0.6667000000000001, max_iter=400, momentum=0.2777777777777778, solver=lbfgs; total time=  23.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(455, 455), learning_rate_init=0.6667000000000001, max_iter=400, momentum=0.2777777777777778, solver=lbfgs; total time=  27.9s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(663, 663), learning_rate_init=0.5556, max_iter=3431, momentum=0.9, solver=adam; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=logistic, hidden_layer_sizes=(585, 585), learning_rate_init=0.8889, max_iter=3052, momentum=0.18888888888888888, solver=adam; total time=  22.2s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(663, 663), learning_rate_init=0.5556, max_iter=3431, momentum=0.9, solver=adam; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=logistic, hidden_layer_sizes=(585, 585), learning_rate_init=0.8889, max_iter=3052, momentum=0.18888888888888888, solver=adam; total time=  25.8s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(487, 487, 487), learning_rate_init=0.6667000000000001, max_iter=1536, momentum=0.2777777777777778, solver=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(487, 487, 487), learning_rate_init=0.6667000000000001, max_iter=1536, momentum=0.2777777777777778, solver=sgd; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(512, 512), learning_rate_init=0.5556, max_iter=400, momentum=0.7222222222222222, solver=sgd; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(512, 512), learning_rate_init=0.5556, max_iter=400, momentum=0.7222222222222222, solver=sgd; total time= 1.0min\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(506,), learning_rate_init=0.8889, max_iter=1726, momentum=0.5444444444444445, solver=lbfgs; total time=   5.0s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(506,), learning_rate_init=0.8889, max_iter=1726, momentum=0.5444444444444445, solver=lbfgs; total time=   6.6s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(818, 818, 818), learning_rate_init=0.33340000000000003, max_iter=1915, momentum=0.18888888888888888, solver=lbfgs; total time=  38.4s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(818, 818, 818), learning_rate_init=0.33340000000000003, max_iter=1915, momentum=0.18888888888888888, solver=lbfgs; total time=  40.0s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(592, 592), learning_rate_init=0.7778, max_iter=3810, momentum=0.8111111111111111, solver=adam; total time=   2.5s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(592, 592), learning_rate_init=0.7778, max_iter=3810, momentum=0.8111111111111111, solver=adam; total time=   2.6s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(734, 734), learning_rate_init=0.6667000000000001, max_iter=2673, momentum=0.8111111111111111, solver=adam; total time=   4.3s\n",
      "[CV] END activation=relu, hidden_layer_sizes=(734, 734), learning_rate_init=0.6667000000000001, max_iter=2673, momentum=0.8111111111111111, solver=adam; total time=   4.4s\n",
      "[CV] END activation=logistic, hidden_layer_sizes=(593, 593, 593), learning_rate_init=1.0, max_iter=2484, momentum=0.3666666666666667, solver=lbfgs; total time= 1.1min\n",
      "[CV] END activation=identity, hidden_layer_sizes=(686, 686, 686), learning_rate_init=0.4445, max_iter=968, momentum=0.2777777777777778, solver=adam; total time=   5.5s\n",
      "[CV] END activation=identity, hidden_layer_sizes=(686, 686, 686), learning_rate_init=0.4445, max_iter=968, momentum=0.2777777777777778, solver=adam; total time=   5.9s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(657, 657, 657), learning_rate_init=0.4445, max_iter=968, momentum=0.1, solver=sgd; total time=   4.1s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(657, 657, 657), learning_rate_init=0.4445, max_iter=968, momentum=0.1, solver=sgd; total time=   5.4s\n",
      "[CV] END activation=logistic, hidden_layer_sizes=(478,), learning_rate_init=0.7778, max_iter=2484, momentum=0.4555555555555556, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=logistic, hidden_layer_sizes=(478,), learning_rate_init=0.7778, max_iter=2484, momentum=0.4555555555555556, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=logistic, hidden_layer_sizes=(593, 593, 593), learning_rate_init=1.0, max_iter=2484, momentum=0.3666666666666667, solver=lbfgs; total time= 1.2min\n",
      "[CV] END activation=logistic, hidden_layer_sizes=(800, 800), learning_rate_init=0.0001, max_iter=3621, momentum=0.2777777777777778, solver=sgd; total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/numpy/core/_methods.py:118: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=logistic, hidden_layer_sizes=(800, 800), learning_rate_init=0.0001, max_iter=3621, momentum=0.2777777777777778, solver=sgd; total time=  22.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_base.py:173: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/utils/extmath.py:208: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1347) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=identity, hidden_layer_sizes=(591,), learning_rate_init=0.2223, max_iter=1347, momentum=0.2777777777777778, solver=sgd; total time=  37.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1347) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=identity, hidden_layer_sizes=(591,), learning_rate_init=0.2223, max_iter=1347, momentum=0.2777777777777778, solver=sgd; total time=  37.0s\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(635, 635, 635), learning_rate_init=0.0001, max_iter=3810, momentum=0.3666666666666667, solver=lbfgs; total time= 1.2min\n",
      "[CV] END activation=tanh, hidden_layer_sizes=(635, 635, 635), learning_rate_init=0.0001, max_iter=3810, momentum=0.3666666666666667, solver=lbfgs; total time= 1.3min\n",
      "[CV] END activation=logistic, hidden_layer_sizes=(519, 519, 519), learning_rate_init=0.33340000000000003, max_iter=2294, momentum=0.5444444444444445, solver=adam; total time=  27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (968) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=identity, hidden_layer_sizes=(521, 521, 521), learning_rate_init=1.0, max_iter=968, momentum=0.8111111111111111, solver=sgd; total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (968) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=identity, hidden_layer_sizes=(521, 521, 521), learning_rate_init=1.0, max_iter=968, momentum=0.8111111111111111, solver=sgd; total time= 4.1min\n",
      "[CV] END activation=logistic, hidden_layer_sizes=(519, 519, 519), learning_rate_init=0.33340000000000003, max_iter=2294, momentum=0.5444444444444445, solver=adam; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1915) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(763, 763, 763), learning_rate_init=0.2223, max_iter=1915, momentum=0.7222222222222222, solver=sgd; total time= 6.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1915) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "8 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [             nan              nan -3.51815561e-002 -4.34592986e+127\n",
      " -6.50380992e+002 -1.27524247e+001 -1.65400216e+080 -5.26640211e-002\n",
      " -2.57151594e+083 -2.98295472e+000 -7.70704793e+001              nan\n",
      " -1.37721677e+109 -3.50648680e-002 -4.80357522e-002 -4.42836291e-002\n",
      " -2.31825283e+010 -1.91920602e+001 -2.86458877e+014 -1.33921627e+105\n",
      " -5.02156021e-002 -8.52941447e+109 -1.13209726e-001              nan\n",
      " -1.87580869e-001]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, hidden_layer_sizes=(763, 763, 763), learning_rate_init=0.2223, max_iter=1915, momentum=0.7222222222222222, solver=sgd; total time= 7.2min\n",
      "Tempo de execução: 499.37 segundos.\n",
      "**Multi-Layer Perceptron (Neural Network) Resultados (Depois do Tuning):**\n",
      "Melhores Parametros: {'solver': 'lbfgs', 'momentum': 0.3666666666666667, 'max_iter': 2484, 'learning_rate_init': 1.0, 'hidden_layer_sizes': (593, 593, 593), 'activation': 'logistic'}\n",
      "MSE: 0.0307\n",
      "RMSE: 0.1753\n",
      "R2: 0.7252\n",
      "\n",
      "\n",
      "**Support Vector Regression (SVR) Resultados (Antes do Tuning):**\n",
      "MSE: 0.0401\n",
      "RMSE: 0.2002\n",
      "R2: 0.6417\n",
      "\n",
      "_Realizando Tuning do Modelo: Support Vector Regression (SVR)_\n",
      "Usando subset\n",
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
      "[CV] END ....C=10000, coef0=0.01, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=1e-05, coef0=0.5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .......C=0.001, coef0=0.5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .......C=0.001, coef0=0.5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .......C=1e-05, coef0=0.5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ........C=1, coef0=0.5, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....C=10000, coef0=0.01, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....C=0.001, coef0=0.5, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=1, coef0=0.5, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....C=0.001, coef0=0.5, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...C=10000, coef0=0.01, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....C=10000, coef0=0.5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...C=10000, coef0=0.01, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....C=10000, coef0=0.5, gamma=scale, kernel=linear; total time=   0.0s[CV] END ...C=0.001, coef0=0.01, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "\n",
      "[CV] END ...C=0.001, coef0=0.01, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......C=1000, coef0=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ......C=1000, coef0=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .........C=0.1, coef0=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....C=0.001, coef0=10, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=0.001, coef0=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .........C=0.1, coef0=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....C=0.001, coef0=10, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ............C=10, coef0=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......C=0.001, coef0=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ......C=0.001, coef0=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ............C=10, coef0=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........C=10, coef0=0.5, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......C=0.001, coef0=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....C=0.001, coef0=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ........C=10, coef0=0.5, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....C=0.001, coef0=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........C=0.1, coef0=0.5, gamma=scale, kernel=rbf; total time=   0.0s[CV] END .....C=0.0001, coef0=0.01, gamma=scale, kernel=poly; total time=   0.0s\n",
      "\n",
      "[CV] END .........C=10, coef0=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .............C=1, coef0=10, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .......C=0.01, coef0=10, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....C=0.0001, coef0=0.01, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .............C=1, coef0=10, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .........C=10, coef0=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .......C=0.01, coef0=10, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........C=0.1, coef0=0.5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........C=0.01, coef0=0.5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........C=1, coef0=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........C=0.01, coef0=0.5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........C=1, coef0=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .......C=0.01, coef0=0.01, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .........C=0.01, coef0=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........C=0.01, coef0=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......C=0.01, coef0=0.01, gamma=scale, kernel=poly; total time=   0.0s\n",
      "Tempo de execução: 0.16 segundos.\n",
      "**Support Vector Regression (SVR) Resultados (Depois do Tuning):**\n",
      "Melhores Parametros: {'kernel': 'linear', 'gamma': 'scale', 'coef0': 0.5, 'C': 10000}\n",
      "MSE: 0.0415\n",
      "RMSE: 0.2037\n",
      "R2: 0.6291\n",
      "\n",
      "Resultados salvos em: 'regression_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "test_and_tune_regression_models(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import os\n",
    "# Função para aplicar SBFS e SFFS com cross validation e salvar tabela com resultado.\n",
    "def perform_feature_selection(data, target, model, best_model, method, cv):\n",
    "    n_cpus = multiprocessing.cpu_count()\n",
    "    # Criando o objeto de seleção de features\n",
    "    if method == 'SBFS':\n",
    "        sfs = SFS(model,\n",
    "                  k_features=\"best\",\n",
    "                  forward=False,\n",
    "                  floating=True,\n",
    "                  verbose=2,\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  cv=cv,\n",
    "                  n_jobs=n_cpus)\n",
    "    elif method == 'SFFS':\n",
    "        sfs = SFS(model,\n",
    "                  k_features=\"best\",\n",
    "                  forward=True,\n",
    "                  floating=True,\n",
    "                  verbose=2,\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  cv=cv,\n",
    "                  n_jobs=n_cpus)\n",
    "    # Aplicando o método de seleção de features\n",
    "    sfs = sfs.fit(data, target)\n",
    "    # Salvando o resultado em um dataframe\n",
    "    df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "\n",
    "    # Definindo nome do arquivo para salvar as features selecionadas em formato CSV\n",
    "    if os.path.exists(f\"results/{method}_{best_model}.csv\"):\n",
    "        i = 1\n",
    "        while os.path.exists(f\"results/{method}_{best_model}_{i}.csv\"):\n",
    "            i += 1\n",
    "        file_name_csv = f\"results/{method}_{best_model}_{i}.csv\"\n",
    "    else:\n",
    "        file_name_csv = f\"results/{method}_{best_model}.csv\"\n",
    "\n",
    "    # Salvando o dataframe em um arquivo CSV\n",
    "    df.to_csv(file_name_csv, index=False)\n",
    "\n",
    "    # Definindo nome do arquivo para salvar as features selecionadas em formato TXT\n",
    "    if os.path.exists(f\"results/{method}_{best_model}.txt\"):\n",
    "        i = 1\n",
    "        while os.path.exists(f\"results/{method}_{best_model}_{i}.txt\"):\n",
    "            i += 1\n",
    "        file_name_txt = f\"results/{method}_{best_model}_{i}.txt\"\n",
    "    else:\n",
    "        file_name_txt = f\"results/{method}_{best_model}.txt\"\n",
    "\n",
    "    # Salvando as features selecionadas e o score em um arquivo TXT\n",
    "    with open(file_name_txt, 'w') as file:\n",
    "        file.write(f\"Selected Features: {', '.join(sfs.k_feature_names_)}\\n\")\n",
    "        file.write(f\"Score: {sfs.k_score_}\")\n",
    "\n",
    "    # Plotando o desempenho do modelo para cada combinação de atributos\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(range(1, len(df) + 1), df['avg_score'], marker='o')\n",
    "    ax.set_xlabel('Number of Features')\n",
    "    ax.set_ylabel('Average Score')\n",
    "    ax.set_title('Performance of Model with Feature Selection')\n",
    "    plt.xticks(range(1, len(df) + 1))\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Definindo nome do arquivo para salvar o gráfico\n",
    "    if os.path.exists(f\"results/{method}_{best_model}.png\"):\n",
    "        i = 1\n",
    "        while os.path.exists(f\"results/{method}_{best_model}_{i}.png\"):\n",
    "            i += 1\n",
    "        file_name_plot = f\"results/{method}_{best_model}_{i}.png\"\n",
    "    else:\n",
    "        file_name_plot = f\"results/{method}_{best_model}.png\"\n",
    "\n",
    "    # Salvando o gráfico em um arquivo PNG\n",
    "    plt.savefig(file_name_plot)\n",
    "\n",
    "    # Retornando as features selecionadas e o score\n",
    "    return sfs.k_feature_names_, sfs.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "/home/apo-note/anaconda3/envs/bic/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "SequentialFeatureSelector has not been fitted, yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m MLPRegressor(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3666666666666667\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2484\u001b[39m, learning_rate_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, hidden_layer_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m593\u001b[39m, \u001b[38;5;241m593\u001b[39m, \u001b[38;5;241m593\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Aplicando o método de seleção de features\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m features, score \u001b[38;5;241m=\u001b[39m \u001b[43mperform_feature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMLPRegressor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSFFS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 29\u001b[0m, in \u001b[0;36mperform_feature_selection\u001b[0;34m(data, target, model, best_model, method, cv)\u001b[0m\n\u001b[1;32m     27\u001b[0m sfs \u001b[38;5;241m=\u001b[39m sfs\u001b[38;5;241m.\u001b[39mfit(data, target)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Salvando o resultado em um dataframe\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[43msfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metric_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Definindo nome do arquivo para salvar as features selecionadas em formato CSV\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/bic/lib/python3.12/site-packages/mlxtend/feature_selection/sequential_feature_selector.py:879\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.get_metric_dict\u001b[0;34m(self, confidence_interval)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_metric_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, confidence_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m):\n\u001b[1;32m    857\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return metric dictionary\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \n\u001b[1;32m    859\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    877\u001b[0m \n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 879\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     fdict \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubsets_)\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m fdict:\n",
      "File \u001b[0;32m~/anaconda3/envs/bic/lib/python3.12/site-packages/mlxtend/feature_selection/sequential_feature_selector.py:898\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._check_fitted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_fitted\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted:\n\u001b[0;32m--> 898\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    899\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequentialFeatureSelector has not been\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m fitted, yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    900\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: SequentialFeatureSelector has not been fitted, yet."
     ]
    }
   ],
   "source": [
    "#'solver': 'lbfgs', 'momentum': 0.3666666666666667, 'max_iter': 2484, 'learning_rate_init': 1.0, 'hidden_layer_sizes': (593, 593, 593), 'activation': 'logistic'\n",
    "# Definindo o modelo de regressão\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = MLPRegressor(solver='lbfgs', momentum=0.3666666666666667, max_iter=2484, learning_rate_init=1.0, hidden_layer_sizes=(593, 593, 593), activation='logistic')\n",
    "\n",
    "# Aplicando o método de seleção de features\n",
    "features, score = perform_feature_selection(X_train, y_train, model, 'MLPRegressor', 'SFFS', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_negative_likelihood_ratio',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'neg_root_mean_squared_log_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'positive_likelihood_ratio',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import get_scorer_names\n",
    "get_scorer_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
